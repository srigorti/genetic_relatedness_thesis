{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout,Activation\n",
    "from keras.layers import Reshape, Flatten\n",
    "from keras.layers import Convolution2D,Conv2D, MaxPooling2D, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import *\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import *\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import datetime, time, json\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r'C:\\Users\\TejaDikshitulu\\Documents\\COURSEWORK\\Comp_Bio_Research\\eggs_dataset'\n",
    "path2 = r'C:\\Users\\TejaDikshitulu\\Documents\\COURSEWORK\\Comp_Bio_Research\\eggs_dataset_resized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing = os.listdir(path1)\n",
    "num_samples = np.size(listing)\n",
    "#print(num_samples)\n",
    "\n",
    "img_rows = 50\n",
    "img_cols = 50\n",
    "for file in listing:\n",
    "    im = Image.open(path1 + '\\\\' + file)\n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')\n",
    "    gray.save(path2 + '\\\\' + file, \"JPEG\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imlist = os.listdir(path2)\n",
    "\n",
    "im1 = np.array(Image.open(path2 + '\\\\' + imlist[0]))\n",
    "m,n = im1.shape[0:2]\n",
    "imnbr = len(imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "immatrix = np.array([np.array(Image.open(path2 + '\\\\' + im2)).flatten() for im2 in imlist], 'f')\n",
    "\n",
    "#print(immatrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.ones((num_samples,),dtype = int)\n",
    "\n",
    "#print(label)\n",
    "\n",
    "os.chdir(r'C:\\Users\\TejaDikshitulu\\Documents\\COURSEWORK\\Comp_Bio_Research\\eggs_dataset_resized')\n",
    "for file in glob.glob('*'):\n",
    "    if \"Army\" in file:\n",
    "        img_index = imlist.index(file)\n",
    "        label[img_index] = 0\n",
    "    elif \"CLFM\" in file:\n",
    "        img_index = imlist.index(file)\n",
    "        label[img_index] = 1\n",
    "        #count = count + 1\n",
    "    elif \"Muk01\" in file:\n",
    "        img_index = imlist.index(file)\n",
    "        label[img_index] = 2\n",
    "    elif \"MUK01\" in file:\n",
    "        img_index = imlist.index(file)\n",
    "        label[img_index] = 2\n",
    "    elif \"SBB\" in file:\n",
    "        img_index = imlist.index(file)\n",
    "        label[img_index] = 3\n",
    "\n",
    "#print(len(label))\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[249. 255. 255. ... 255. 255. 255.]\n",
      " [255. 252. 249. ... 255. 255. 255.]\n",
      " [253. 254. 255. ... 255. 255. 255.]\n",
      " ...\n",
      " [255. 255. 255. ... 255. 255. 255.]\n",
      " [255. 255. 255. ... 255. 255. 255.]\n",
      " [255. 255. 254. ... 255. 255. 255.]]\n"
     ]
    }
   ],
   "source": [
    "#print(label)\n",
    "\n",
    "data, Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data, Label]\n",
    "\n",
    "\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f86bea3ba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = immatrix[102].reshape(img_rows, img_cols)\n",
    "plt.imshow(img)\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "#print(train_data[0].shape)\n",
    "#print(train_data[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X,y) = (train_data[0], train_data[1])\n",
    "\n",
    "X_train,X_test, Y_train,Y_test =train_test_split(X, y, test_size = 0.1, random_state=4)\n",
    "\n",
    "X_train= X_train.reshape(X_train.shape[0],1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test/= 255\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    n = min([len(digit_indices[d]) for d in range(nb_classes)]) - 1\n",
    "    #print(n)\n",
    "    #print(\"I am inside create pairs\", x[3])\n",
    "    for d in range(nb_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, nb_classes)\n",
    "            dn = (d + inc) % nb_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    #print(\"printing pairs\", pairs)\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "digit_indices = [np.where(Y_train == i)[0] for i in range(nb_classes)]\n",
    "tr_pairs, tr_y = create_pairs(X_train, digit_indices)\n",
    "\n",
    "#digit_indices = [np.where(Y_val == i)[0] for i in range(nb_classes)]\n",
    "#val_pairs, val_y = create_pairs(X_val, digit_indices)\n",
    "\n",
    "digit_indices_test = [np.where(Y_test == i)[0] for i in range(nb_classes)]\n",
    "test_pairs, test_y = create_pairs(X_test, digit_indices_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_list = X_train.tolist()\n",
    "\n",
    "#print(\"to_list is done\")\n",
    "\n",
    "#img1 = []\n",
    "#img2 = []\n",
    "\n",
    "#for i in range(len(X_train)-1):\n",
    "#    for j in range(i+1, len(X_train)):\n",
    "#        img1.append(train_list[i][:])\n",
    "#        img2.append(train_list[j][:])\n",
    "\n",
    "\n",
    "#print(\"img1, img2\", type(img1), type(img2))\n",
    "#m = len(img1)\n",
    "#n = len(img2)\n",
    "\n",
    "#img1_array = np.asarray(img1)\n",
    "#print(\"I do reshape\", img1_array.shape)\n",
    "#img2_array = np.array(img2).reshape(n,1,img_rows,img_cols)\n",
    "#print(\"I do reshape\", img2_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(X_train1))\n",
    "#print(len(y_train))\n",
    "#print(y_train.shape)\n",
    "\n",
    "#x = y_train[0] - y_train[1]\n",
    "\n",
    "#z = np.array(x).reshape(1,1)\n",
    "\n",
    "#print(z.shape)\n",
    "#print(y_train[0])\n",
    "#print(y_train[1])\n",
    "#print(y_train[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img1_train = X_train[:,0]\n",
    "#Q2_train = X_train[:,1]\n",
    "\n",
    "#print(img1_train)\n",
    "#print(Q2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) +\n",
    "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "nb_classes = 4\n",
    "nb_epoch = 20\n",
    "\n",
    "img_rows, img_cols = 50,50\n",
    "\n",
    "img_channels = 1\n",
    "\n",
    "nb_filters = 324\n",
    "nb_pool = 2\n",
    "nb_conv = 3\n",
    "\n",
    "MODEL_WEIGHTS_FILE = 'egg_pairs_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TejaDikshitulu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(324, 3, input_shape=(1, 50, 50..., data_format=\"channels_first\", padding=\"valid\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters, nb_conv, border_mode = 'valid', input_shape=(1, img_rows, img_cols), data_format = 'channels_first'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "processed_a = model(left_input)\n",
    "processed_b = model(right_input)\n",
    "\n",
    "distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "siamese_net = Model([left_input, right_input], distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 144 samples, validate on 16 samples\n",
      "Epoch 1/20\n",
      "144/144 [==============================] - 51s 352ms/step - loss: 0.3041 - accuracy: 0.4375 - val_loss: 0.4816 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "144/144 [==============================] - 56s 387ms/step - loss: 0.2819 - accuracy: 0.5208 - val_loss: 0.4816 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "144/144 [==============================] - 47s 325ms/step - loss: 0.2784 - accuracy: 0.4861 - val_loss: 0.4816 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "Epoch 4/20\n",
      "144/144 [==============================] - 50s 349ms/step - loss: 0.2865 - accuracy: 0.4306 - val_loss: 0.4816 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "144/144 [==============================] - 54s 377ms/step - loss: 0.2936 - accuracy: 0.4375 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.500000213738531e-05.\n",
      "Epoch 6/20\n",
      "144/144 [==============================] - 50s 349ms/step - loss: 0.2980 - accuracy: 0.4097 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "144/144 [==============================] - 47s 324ms/step - loss: 0.2824 - accuracy: 0.4931 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.3500000204658135e-05.\n",
      "Epoch 8/20\n",
      "144/144 [==============================] - 48s 336ms/step - loss: 0.2888 - accuracy: 0.4722 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 9/20\n",
      "144/144 [==============================] - 45s 315ms/step - loss: 0.2572 - accuracy: 0.5417 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.050000006827758e-06.\n",
      "Epoch 10/20\n",
      "144/144 [==============================] - 45s 313ms/step - loss: 0.2827 - accuracy: 0.5139 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 11/20\n",
      "144/144 [==============================] - 46s 318ms/step - loss: 0.2660 - accuracy: 0.5764 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.2149999747634864e-06.\n",
      "Epoch 12/20\n",
      "144/144 [==============================] - 58s 401ms/step - loss: 0.2869 - accuracy: 0.4583 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "144/144 [==============================] - 60s 417ms/step - loss: 0.2779 - accuracy: 0.5486 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.644999992502562e-07.\n",
      "Epoch 14/20\n",
      "144/144 [==============================] - 51s 357ms/step - loss: 0.2959 - accuracy: 0.4722 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "144/144 [==============================] - 49s 343ms/step - loss: 0.2729 - accuracy: 0.5069 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0935000318568199e-07.\n",
      "Epoch 16/20\n",
      "144/144 [==============================] - 51s 354ms/step - loss: 0.2909 - accuracy: 0.4722 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 17/20\n",
      "144/144 [==============================] - 47s 327ms/step - loss: 0.2758 - accuracy: 0.5903 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.280500138203024e-08.\n",
      "Epoch 18/20\n",
      "144/144 [==============================] - 47s 324ms/step - loss: 0.2551 - accuracy: 0.5764 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "Epoch 19/20\n",
      "144/144 [==============================] - 52s 363ms/step - loss: 0.2821 - accuracy: 0.5208 - val_loss: 0.4815 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.841500414609073e-09.\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "#rms = keras.optimizers.RMSprop()\n",
    "opt = keras.optimizers.SGD(lr = 0.0005)\n",
    "siamese_net.compile(loss=contrastive_loss, optimizer=opt, metrics=[accuracy])\n",
    "\n",
    "# train\n",
    "patience = 5\n",
    "#model_name = 'MobileNet'\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append((logs.get('loss'), logs.get(\"val_loss\")))\n",
    "        \n",
    "history = LossHistory()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(MODEL_WEIGHTS_FILE, verbose=0, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.3, patience=2, verbose=1)\n",
    "\n",
    "h = siamese_net.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=32,\n",
    "          epochs=epochs,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "          callbacks=[history, early_stopping,checkpointer, reduce_lr],\n",
    "          shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_net.load_weights(MODEL_WEIGHTS_FILE)\n",
    "loss, accuracy = siamese_net.evaluate([test_pairs[:,0], test_pairs[:,1]], test_y, verbose=1)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#training_start_time = time()\n",
    "\n",
    "#train_list = X_train.tolist()\n",
    "\n",
    "#for i in range(len(X_train)-1):\n",
    "#    for j in range(i+1, len(X_train)):\n",
    "        #img1.append(train_list[i][:])\n",
    "        #img2.append(train_list[j][:])\n",
    "#        img1 = X_train[i][:]\n",
    "#        img2 = X_train[j][:]\n",
    "#        img1_train = img1.reshape(1,1, img_rows, img_cols)\n",
    "#        img2_train = img2.reshape(1,1, img_rows, img_cols)\n",
    "#        y_1 = y_train[i] - y_train[j]\n",
    "#        y_train1 = np.array(y_1).reshape(1,1)\n",
    "#        malstm_trained = siamese_net.fit([img1_train, img2_train],y_train1,nb_epoch=nb_epoch, verbose = 1, batch_size = batch_size,callbacks=callbacks_list)\n",
    "\n",
    "        \n",
    "#print(\"Training time finished.\\n{} epochs in {}\".format(nb_epoch, datetime.timedelta(seconds=time()-training_start_time)))\n",
    "#m = len(img1)\n",
    "#n = len(img2)\n",
    "#img1_array = np.array(img1).reshape(m,1,img_rows,img_cols)\n",
    "#img2_array = np.array(img2).reshape(n,1,img_rows,img_cols)\n",
    "\n",
    "#for img1 in np.nditer(X_train, flags = ['external_loop']):\n",
    "#    for img2 in np.nditer(X_train, flags = ['external_loop']):\n",
    " #       print(type(img1))\n",
    "        #print(img1)\n",
    " #       print(img1.shape)\n",
    "        #print(len(X_train[0]))\n",
    "        #print(X_train.shape)\n",
    "  #      img1_train = img1.reshape(X_train[0],1, img_rows, img_cols)\n",
    "   #     print(img1_train.shape)\n",
    "        #img2_r = image2.reshape(1, img_rows, img_cols)\n",
    "        #img1_train = img1_r[238,:,:,:]\n",
    "        #img2_train = img2_r[238,:,:,:]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape = X_train.shape[1:]\n",
    "#left_input = Input(input_shape)\n",
    "#right_input = Input(input_shape)\n",
    "\n",
    "#convnet = Sequential()\n",
    "\n",
    "#convnet.add(Convolution2D(nb_filters, nb_conv, border_mode = 'valid', input_shape=(1, img_rows, img_cols), data_format = 'channels_first'))\n",
    "#convout1 = Activation('relu')\n",
    "#convnet.add(convout1)\n",
    "#convnet.add(Convolution2D(nb_filters,nb_conv,nb_conv))\n",
    "#convout2 = Activation('relu')\n",
    "#convnet.add(convout2)\n",
    "#convnet.add(MaxPooling2D(pool_size = (nb_pool, nb_pool)))\n",
    "#convnet.add(Dropout(0.5))\n",
    "\n",
    "#convnet.add(Flatten())\n",
    "#convnet.add(Dense(128))\n",
    "#convnet.add(Activation('relu'))\n",
    "#convnet.add(Dropout(0.5))\n",
    "#convnet.add(Dense(nb_classes))\n",
    "\n",
    "#processed_a = convnet(left_input)\n",
    "#processed_b = convnet(right_input)\n",
    "\n",
    "#distance = Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "#siamese_net = Model([left_input, right_input], distance)\n",
    "\n",
    "#L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "#prediction = Dense(1, activation = 'sigmoid')(L1_distance)\n",
    "\n",
    "#malstm_distance = Merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), output_shape=lambda x: (x[0][0], 1))([question11_op, question22_op])\n",
    "\n",
    "#siamese_net.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "#filepath=\"weights.best.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(digit_indices[0])\n",
    "#print(digit_indices[1])\n",
    "#print(digit_indices[2])\n",
    "#print(digit_indices[3])\n",
    "#print(digit_indices[4])\n",
    "#print(min([len(digit_indices[d]) for d in range(nb_classes)]))\n",
    "\n",
    "\n",
    "#print(type(tr_pairs))\n",
    "\n",
    "#print(tr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(malstm_trained.history['val_acc']))\n",
    "#print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
